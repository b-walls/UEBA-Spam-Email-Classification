{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c00b4d9-9c21-4632-a932-d8397812935f",
   "metadata": {},
   "source": [
    "# Imports and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6d7600-7438-4c24-ab0a-057f312b08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b031ce5b-bd6e-42fa-bff7-33e57611e6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Spam/Ham</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>christmas tree farm pictures</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vastar resources , inc .</td>\n",
       "      <td>gary , production from the high island larger ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>- calpine daily gas nomination 1 . doc</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>re : issue</td>\n",
       "      <td>fyi - see note below - already done .\\nstella\\...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi .\\n- - - - - - - - - - - - - - - - - - - -...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1999-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33711</th>\n",
       "      <td>33711</td>\n",
       "      <td>= ? iso - 8859 - 1 ? q ? good _ news _ c = eda...</td>\n",
       "      <td>hello , welcome to gigapharm onlinne shop .\\np...</td>\n",
       "      <td>spam</td>\n",
       "      <td>2005-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33712</th>\n",
       "      <td>33712</td>\n",
       "      <td>all prescript medicines are on special . to be...</td>\n",
       "      <td>i got it earlier than expected and it was wrap...</td>\n",
       "      <td>spam</td>\n",
       "      <td>2005-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33713</th>\n",
       "      <td>33713</td>\n",
       "      <td>the next generation online pharmacy .</td>\n",
       "      <td>are you ready to rock on ? let the man in you ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>2005-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33714</th>\n",
       "      <td>33714</td>\n",
       "      <td>bloow in 5 - 10 times the time</td>\n",
       "      <td>learn how to last 5 - 10 times longer in\\nbed ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>2005-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33715</th>\n",
       "      <td>33715</td>\n",
       "      <td>dear sir , i am interested in it</td>\n",
       "      <td>hi : )\\ndo you need some softwares ? i can giv...</td>\n",
       "      <td>spam</td>\n",
       "      <td>2005-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33716 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Message ID                                            Subject  \\\n",
       "0               0                       christmas tree farm pictures   \n",
       "1               1                           vastar resources , inc .   \n",
       "2               2                       calpine daily gas nomination   \n",
       "3               3                                         re : issue   \n",
       "4               4                          meter 7268 nov allocation   \n",
       "...           ...                                                ...   \n",
       "33711       33711  = ? iso - 8859 - 1 ? q ? good _ news _ c = eda...   \n",
       "33712       33712  all prescript medicines are on special . to be...   \n",
       "33713       33713              the next generation online pharmacy .   \n",
       "33714       33714                     bloow in 5 - 10 times the time   \n",
       "33715       33715                   dear sir , i am interested in it   \n",
       "\n",
       "                                                 Message Spam/Ham        Date  \n",
       "0                                                    NaN      ham  1999-12-10  \n",
       "1      gary , production from the high island larger ...      ham  1999-12-13  \n",
       "2                 - calpine daily gas nomination 1 . doc      ham  1999-12-14  \n",
       "3      fyi - see note below - already done .\\nstella\\...      ham  1999-12-14  \n",
       "4      fyi .\\n- - - - - - - - - - - - - - - - - - - -...      ham  1999-12-14  \n",
       "...                                                  ...      ...         ...  \n",
       "33711  hello , welcome to gigapharm onlinne shop .\\np...     spam  2005-07-29  \n",
       "33712  i got it earlier than expected and it was wrap...     spam  2005-07-29  \n",
       "33713  are you ready to rock on ? let the man in you ...     spam  2005-07-30  \n",
       "33714  learn how to last 5 - 10 times longer in\\nbed ...     spam  2005-07-30  \n",
       "33715  hi : )\\ndo you need some softwares ? i can giv...     spam  2005-07-31  \n",
       "\n",
       "[33716 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data\\enron_spam_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f72852b-a01e-4d20-94a4-ef8b32772675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessary columns\n",
    "df = df.drop(columns='Message ID')\n",
    "df = df.drop(columns='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0381c249-d9c0-4195-8c4c-49cba003974d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Spam/Ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vastar resources , inc .</td>\n",
       "      <td>gary , production from the high island larger ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>- calpine daily gas nomination 1 . doc</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re : issue</td>\n",
       "      <td>fyi - see note below - already done .\\nstella\\...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi .\\n- - - - - - - - - - - - - - - - - - - -...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcmullen gas for 11 / 99</td>\n",
       "      <td>jackie ,\\nsince the inlet to 3 river plant is ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Subject  \\\n",
       "0      vastar resources , inc .   \n",
       "1  calpine daily gas nomination   \n",
       "2                    re : issue   \n",
       "3     meter 7268 nov allocation   \n",
       "4      mcmullen gas for 11 / 99   \n",
       "\n",
       "                                             Message Spam/Ham  \n",
       "0  gary , production from the high island larger ...      ham  \n",
       "1             - calpine daily gas nomination 1 . doc      ham  \n",
       "2  fyi - see note below - already done .\\nstella\\...      ham  \n",
       "3  fyi .\\n- - - - - - - - - - - - - - - - - - - -...      ham  \n",
       "4  jackie ,\\nsince the inlet to 3 river plant is ...      ham  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop NaNs and reset index\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4908a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix dtypes\n",
    "df['Message'] = df['Message'].astype(str)\n",
    "df['Subject'] = df['Subject'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd83e8db-37e9-4903-ae96-51632e977668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename classification column for clarity\n",
    "df = df.rename(columns={'Spam/Ham': 'Class'})\n",
    "\n",
    "# remap spam to 1 and ham to 0\n",
    "df['Class'] = df['Class'].map({'spam': 1, 'ham': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14110bca-02e9-49b0-9c7a-9b2d0ab51532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1    16614\n",
       "0    16493\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of classes\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59437abc-2efb-4e34-bc06-4e6fc36a9cfb",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca13e6-1d26-4ed2-a8b7-867eedb04157",
   "metadata": {},
   "source": [
    "## Count features commonly in spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f928b420-ad8f-41bf-99a5-ff1f43dad9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def count_url(text):\n",
    "    # count the occurrences of 'http', 'https', and 'www'\n",
    "    count_http = len(re.findall(r'http', text))\n",
    "    count_https = len(re.findall(r'https', text))\n",
    "    count_www = len(re.findall(r'www', text))\n",
    "    \n",
    "    # return the total count of urls in a new column\n",
    "    return count_http + count_https + count_www"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f2897a5-2c62-4eb7-89e5-748eb7901bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_special_chars(text):\n",
    "    return len(re.findall(r'[!$%&]', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e4a9fd-111f-468e-8465-9f2f122ab441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_urgency_words(text):\n",
    "    urgency_words = [\n",
    "        \"immediate\", \"urgent\", \"critical\", \"important\", \"now\", \"ASAP\", \"as soon as possible\",\n",
    "        \"emergency\", \"priority\", \"alert\", \"rush\", \"prompt\", \"hasten\", \"swift\", \"instantly\",\n",
    "        \"right away\", \"without delay\", \"high priority\", \"imminent\", \"pressing\", \"time - sensitive\",\n",
    "        \"expedite\", \"top priority\", \"crucial\", \"vital\", \"necessary\", \"quick\", \"speedy\", \"at once\",\n",
    "        \"rapid\", \"flash\", \"instantaneous\", \"accelerated\", \"breakneck\", \"hurry\", \"immediately\",\n",
    "        \"fast-track\", \"at the earliest\", \"act now\", \"don't delay\", \"on the double\", \"without hesitation\",\n",
    "        \"fast\", \"soon\", \"now or never\", \"urgent action\", \"right now\", \"straightaway\", \"double-time\",\n",
    "        \"speed\", \"express\", \"high-priority\", \"pressing need\", \"at your earliest convenience\", \"this instant\",\n",
    "        \"forthwith\", \"like a shot\", \"snap to it\", \"on the spot\", \"no time to lose\", \"no delay\",\n",
    "        \"in a hurry\", \"right this minute\", \"get going\", \"with haste\"\n",
    "    ]\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    count = sum(1 for word in words if word in urgency_words)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beffb52-8127-476f-9f48-3eb852f852a4",
   "metadata": {},
   "source": [
    "## Other indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a7aa103-8bce-4d52-98cc-291024affa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c17c3f08-b81f-41f7-8d89-128059bf8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_forwarded(text):\n",
    "    if (len(re.findall(r'-', text))) > 9 and len(re.findall(r'forward', text)) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4017717-eaa2-4bd9-bfb9-ffdb76a2db6e",
   "metadata": {},
   "source": [
    "## Create the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff907e40-08f7-45c4-85f5-a1f289ec02f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Class</th>\n",
       "      <th>length_message</th>\n",
       "      <th>length_subject</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>urgent_phrase_count</th>\n",
       "      <th>forwarded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vastar resources , inc .</td>\n",
       "      <td>gary , production from the high island larger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4282</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>- calpine daily gas nomination 1 . doc</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re : issue</td>\n",
       "      <td>fyi - see note below - already done .\\nstella\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi .\\n- - - - - - - - - - - - - - - - - - - -...</td>\n",
       "      <td>0</td>\n",
       "      <td>1124</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcmullen gas for 11 / 99</td>\n",
       "      <td>jackie ,\\nsince the inlet to 3 river plant is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Subject  \\\n",
       "0      vastar resources , inc .   \n",
       "1  calpine daily gas nomination   \n",
       "2                    re : issue   \n",
       "3     meter 7268 nov allocation   \n",
       "4      mcmullen gas for 11 / 99   \n",
       "\n",
       "                                             Message  Class  length_message  \\\n",
       "0  gary , production from the high island larger ...      0            4282   \n",
       "1             - calpine daily gas nomination 1 . doc      0              38   \n",
       "2  fyi - see note below - already done .\\nstella\\...      0            1171   \n",
       "3  fyi .\\n- - - - - - - - - - - - - - - - - - - -...      0            1124   \n",
       "4  jackie ,\\nsince the inlet to 3 river plant is ...      0             534   \n",
       "\n",
       "   length_subject  urls_count  special_chars_count  urgent_phrase_count  \\\n",
       "0              24           0                    1                    1   \n",
       "1              28           0                    0                    0   \n",
       "2              10           0                    0                    0   \n",
       "3              25           0                    0                    0   \n",
       "4              24           0                    0                    3   \n",
       "\n",
       "   forwarded  \n",
       "0          1  \n",
       "1          0  \n",
       "2          1  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# email lengths\n",
    "df['length_message'] = df['Message'].apply(get_length)\n",
    "df['length_subject'] = df['Subject'].apply(get_length)\n",
    "\n",
    "# url counts\n",
    "df['urls_count_message'] = df['Message'].apply(count_url)\n",
    "df['urls_count_subject'] = df['Subject'].apply(count_url)\n",
    "df['urls_count'] = df['urls_count_message'] + df['urls_count_subject']\n",
    "df = df.drop(columns={'urls_count_message', 'urls_count_subject'})\n",
    "\n",
    "# special char counts\n",
    "df['special_chars_count_message'] = df['Message'].apply(count_special_chars)\n",
    "df['special_chars_count_subject'] = df['Subject'].apply(count_special_chars)\n",
    "df['special_chars_count'] = df['special_chars_count_message'] + df['special_chars_count_subject']\n",
    "df = df.drop(columns={'special_chars_count_message', 'special_chars_count_subject'})\n",
    "\n",
    "# urgent phrase counts\n",
    "df['urgent_phrase_count_message'] = df['Message'].apply(count_urgency_words)\n",
    "df['urgent_phrase_count_subject'] = df['Subject'].apply(count_urgency_words)\n",
    "df['urgent_phrase_count'] = df['urgent_phrase_count_message'] + df['urgent_phrase_count_subject']\n",
    "df = df.drop(columns={'urgent_phrase_count_message', 'urgent_phrase_count_subject'})\n",
    "\n",
    "# forwarded\n",
    "df['forwarded'] = df['Message'].apply(is_forwarded)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9632ef-1a23-442a-bd2f-8445cce6041c",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f7e824-8d83-48a9-bb5f-2ba1a4828c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Remove excessive spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de480f73-c63f-4897-83da-a3518f68b635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Class</th>\n",
       "      <th>length_message</th>\n",
       "      <th>length_subject</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>urgent_phrase_count</th>\n",
       "      <th>forwarded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vastar resources inc</td>\n",
       "      <td>gary production from the high island larger bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>4282</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>calpine daily gas nomination 1 doc</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re issue</td>\n",
       "      <td>fyi see note below already done stella forward...</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi forwarded by lauri a allen hou ect on 12 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>1124</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcmullen gas for 11 99</td>\n",
       "      <td>jackie since the inlet to 3 river plant is shu...</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Subject  \\\n",
       "0          vastar resources inc   \n",
       "1  calpine daily gas nomination   \n",
       "2                      re issue   \n",
       "3     meter 7268 nov allocation   \n",
       "4        mcmullen gas for 11 99   \n",
       "\n",
       "                                             Message  Class  length_message  \\\n",
       "0  gary production from the high island larger bl...      0            4282   \n",
       "1                 calpine daily gas nomination 1 doc      0              38   \n",
       "2  fyi see note below already done stella forward...      0            1171   \n",
       "3  fyi forwarded by lauri a allen hou ect on 12 1...      0            1124   \n",
       "4  jackie since the inlet to 3 river plant is shu...      0             534   \n",
       "\n",
       "   length_subject  urls_count  special_chars_count  urgent_phrase_count  \\\n",
       "0              24           0                    1                    1   \n",
       "1              28           0                    0                    0   \n",
       "2              10           0                    0                    0   \n",
       "3              25           0                    0                    0   \n",
       "4              24           0                    0                    3   \n",
       "\n",
       "   forwarded  \n",
       "0          1  \n",
       "1          0  \n",
       "2          1  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Message'] = df['Message'].apply(clean_text)\n",
    "df['Subject'] = df['Subject'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fe3329a-5689-434c-9021-2ec47d7e8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# stop words\n",
    "# nltk.download('punkt') <------ need these lines to \n",
    "# nltk.download('stopwords') <-- load stopwords\n",
    "stop_words = stopwords.words()\n",
    "\n",
    "# lemmatizer initialization\n",
    "# nltk.download('averaged_perceptron_tagger') <---- need these lines to downnload\n",
    "# nltk.download('wordnet') <----------------------- wordnet used for lemmitization\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04f3c2-bf63-4b8f-b4bf-75940f39523d",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "130322f1-3af9-4450-aec1-83fe35c70a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text, stop_words):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    new_text = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe6ee21-d57f-48cb-9291-feeeb6667cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Message'] = df['Message'].apply(remove_stop_words, stop_words=stop_words)\n",
    "df['Subject'] = df['Subject'].apply(remove_stop_words, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ea245-6840-4840-b485-cb1f9a90578f",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5082896-10cc-46f1-ac7c-c6838b9d3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_email(text, lemmatizer):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7b1fb2e-fda1-48a2-ac20-c7f5242d0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize message line \n",
    "df['Message'] = df['Message'].apply(lemmatize_email, lemmatizer=lemmatizer)\n",
    "\n",
    "# lemmatize subject line\n",
    "df['Subject'] = df['Subject'].apply(lemmatize_email, lemmatizer=lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae81f46-5eee-4320-9592-6fd324de9f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Class</th>\n",
       "      <th>length_message</th>\n",
       "      <th>length_subject</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>urgent_phrase_count</th>\n",
       "      <th>forwarded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vastar resource</td>\n",
       "      <td>gary production high island large block 1 2 co...</td>\n",
       "      <td>0</td>\n",
       "      <td>4282</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>calpine daily gas nomination 1 doc</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issue</td>\n",
       "      <td>fyi note stella forward stella morris hou ect ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi forward lauri hou ect 12 14 99 12 17 pm ki...</td>\n",
       "      <td>0</td>\n",
       "      <td>1124</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcmullen gas 11 99</td>\n",
       "      <td>jackie inlet 3 river plant shut 10 19 99 day f...</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Subject  \\\n",
       "0               vastar resource   \n",
       "1  calpine daily gas nomination   \n",
       "2                         issue   \n",
       "3     meter 7268 nov allocation   \n",
       "4            mcmullen gas 11 99   \n",
       "\n",
       "                                             Message  Class  length_message  \\\n",
       "0  gary production high island large block 1 2 co...      0            4282   \n",
       "1                 calpine daily gas nomination 1 doc      0              38   \n",
       "2  fyi note stella forward stella morris hou ect ...      0            1171   \n",
       "3  fyi forward lauri hou ect 12 14 99 12 17 pm ki...      0            1124   \n",
       "4  jackie inlet 3 river plant shut 10 19 99 day f...      0             534   \n",
       "\n",
       "   length_subject  urls_count  special_chars_count  urgent_phrase_count  \\\n",
       "0              24           0                    1                    1   \n",
       "1              28           0                    0                    0   \n",
       "2              10           0                    0                    0   \n",
       "3              25           0                    0                    0   \n",
       "4              24           0                    0                    3   \n",
       "\n",
       "   forwarded  \n",
       "0          1  \n",
       "1          0  \n",
       "2          1  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77901a79",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ef8c1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14674f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ee534",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbfa1841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2db88a35b649fbb8997ba057f05799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brendan\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Brendan\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3c3136d81d4a2dae3cd123f2d17c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e521bbb1db34712b0541c04193debba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4ae272546446cf951068c765f9ddfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493ee7bb296449f9b0f6eea6c5ca01cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3dde7",
   "metadata": {},
   "source": [
    "## Run Emails through Neural Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c9bd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    scores = logits[0].cpu().detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8337badf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df657c5c75c045ff9f7a66a66123d8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "results = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    msg = row['Message']\n",
    "    subject = row['Subject']\n",
    "    message_scores = polarity_scores(msg)\n",
    "    subject_scores = polarity_scores(subject)\n",
    "    message_results = {\n",
    "        'msg_neg' : message_scores[0],\n",
    "        'msg_neu' : message_scores[1],\n",
    "        'msg_pos' : message_scores[2]\n",
    "    }\n",
    "    subject_results = {\n",
    "        'sub_neg' : subject_scores[0],\n",
    "        'sub_neu' : subject_scores[1],\n",
    "        'sub_pos' : subject_scores[2]\n",
    "    }\n",
    "    results[i] = message_results | subject_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c38792c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_neg</th>\n",
       "      <th>msg_neu</th>\n",
       "      <th>msg_pos</th>\n",
       "      <th>sub_neg</th>\n",
       "      <th>sub_neu</th>\n",
       "      <th>sub_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.906160</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.065139</td>\n",
       "      <td>0.728012</td>\n",
       "      <td>0.206849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035552</td>\n",
       "      <td>0.877274</td>\n",
       "      <td>0.087174</td>\n",
       "      <td>0.051015</td>\n",
       "      <td>0.819466</td>\n",
       "      <td>0.129519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.934020</td>\n",
       "      <td>0.034564</td>\n",
       "      <td>0.265126</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.076759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035840</td>\n",
       "      <td>0.921378</td>\n",
       "      <td>0.042782</td>\n",
       "      <td>0.058819</td>\n",
       "      <td>0.878761</td>\n",
       "      <td>0.062419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078795</td>\n",
       "      <td>0.898731</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>0.874298</td>\n",
       "      <td>0.081979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33102</th>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.128509</td>\n",
       "      <td>0.862844</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.082979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33103</th>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.236931</td>\n",
       "      <td>0.747131</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>0.882739</td>\n",
       "      <td>0.090448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33104</th>\n",
       "      <td>0.042042</td>\n",
       "      <td>0.837309</td>\n",
       "      <td>0.120649</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.705230</td>\n",
       "      <td>0.261970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33105</th>\n",
       "      <td>0.045250</td>\n",
       "      <td>0.870471</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.029581</td>\n",
       "      <td>0.756366</td>\n",
       "      <td>0.214053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33106</th>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.228184</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>0.608512</td>\n",
       "      <td>0.364307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33107 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        msg_neg   msg_neu   msg_pos   sub_neg   sub_neu   sub_pos\n",
       "0      0.017629  0.906160  0.076210  0.065139  0.728012  0.206849\n",
       "1      0.035552  0.877274  0.087174  0.051015  0.819466  0.129519\n",
       "2      0.031416  0.934020  0.034564  0.265126  0.658116  0.076759\n",
       "3      0.035840  0.921378  0.042782  0.058819  0.878761  0.062419\n",
       "4      0.078795  0.898731  0.022474  0.043723  0.874298  0.081979\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "33102  0.008647  0.128509  0.862844  0.030983  0.886038  0.082979\n",
       "33103  0.015938  0.236931  0.747131  0.026812  0.882739  0.090448\n",
       "33104  0.042042  0.837309  0.120649  0.032800  0.705230  0.261970\n",
       "33105  0.045250  0.870471  0.084279  0.029581  0.756366  0.214053\n",
       "33106  0.012002  0.759813  0.228184  0.027181  0.608512  0.364307\n",
       "\n",
       "[33107 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6042b34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Class</th>\n",
       "      <th>length_message</th>\n",
       "      <th>length_subject</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>urgent_phrase_count</th>\n",
       "      <th>forwarded</th>\n",
       "      <th>msg_neg</th>\n",
       "      <th>msg_neu</th>\n",
       "      <th>msg_pos</th>\n",
       "      <th>sub_neg</th>\n",
       "      <th>sub_neu</th>\n",
       "      <th>sub_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vastar resource</td>\n",
       "      <td>gary production high island large block 1 2 co...</td>\n",
       "      <td>0</td>\n",
       "      <td>4282</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.906160</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.065139</td>\n",
       "      <td>0.728012</td>\n",
       "      <td>0.206849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>calpine daily gas nomination 1 doc</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035552</td>\n",
       "      <td>0.877274</td>\n",
       "      <td>0.087174</td>\n",
       "      <td>0.051015</td>\n",
       "      <td>0.819466</td>\n",
       "      <td>0.129519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issue</td>\n",
       "      <td>fyi note stella forward stella morris hou ect ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.934020</td>\n",
       "      <td>0.034564</td>\n",
       "      <td>0.265126</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.076759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi forward lauri hou ect 12 14 99 12 17 pm ki...</td>\n",
       "      <td>0</td>\n",
       "      <td>1124</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035840</td>\n",
       "      <td>0.921378</td>\n",
       "      <td>0.042782</td>\n",
       "      <td>0.058819</td>\n",
       "      <td>0.878761</td>\n",
       "      <td>0.062419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcmullen gas 11 99</td>\n",
       "      <td>jackie inlet 3 river plant shut 10 19 99 day f...</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078795</td>\n",
       "      <td>0.898731</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>0.874298</td>\n",
       "      <td>0.081979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33102</th>\n",
       "      <td>iso 8859 1 news edaliss val edumm vl eoggra</td>\n",
       "      <td>welcome gigapharm onlinne shop prescri linecan...</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.128509</td>\n",
       "      <td>0.862844</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.082979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33103</th>\n",
       "      <td>prescript medicine special precise put buck ba...</td>\n",
       "      <td>earlier expect wrap cautiously impressed speed...</td>\n",
       "      <td>1</td>\n",
       "      <td>803</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.236931</td>\n",
       "      <td>0.747131</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>0.882739</td>\n",
       "      <td>0.090448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33104</th>\n",
       "      <td>generation online pharmacy</td>\n",
       "      <td>ready rock rise solitude show society show tal...</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042042</td>\n",
       "      <td>0.837309</td>\n",
       "      <td>0.120649</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.705230</td>\n",
       "      <td>0.261970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33105</th>\n",
       "      <td>bloow 5 10 time time</td>\n",
       "      <td>learn 5 10 time longer bed read plod net</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>0.870471</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.029581</td>\n",
       "      <td>0.756366</td>\n",
       "      <td>0.214053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33106</th>\n",
       "      <td>dear sir interested</td>\n",
       "      <td>software give link http 6 zk net softyourmeans...</td>\n",
       "      <td>1</td>\n",
       "      <td>304</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.228184</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>0.608512</td>\n",
       "      <td>0.364307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33107 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Subject  \\\n",
       "0                                        vastar resource   \n",
       "1                           calpine daily gas nomination   \n",
       "2                                                  issue   \n",
       "3                              meter 7268 nov allocation   \n",
       "4                                     mcmullen gas 11 99   \n",
       "...                                                  ...   \n",
       "33102        iso 8859 1 news edaliss val edumm vl eoggra   \n",
       "33103  prescript medicine special precise put buck ba...   \n",
       "33104                         generation online pharmacy   \n",
       "33105                               bloow 5 10 time time   \n",
       "33106                                dear sir interested   \n",
       "\n",
       "                                                 Message  Class  \\\n",
       "0      gary production high island large block 1 2 co...      0   \n",
       "1                     calpine daily gas nomination 1 doc      0   \n",
       "2      fyi note stella forward stella morris hou ect ...      0   \n",
       "3      fyi forward lauri hou ect 12 14 99 12 17 pm ki...      0   \n",
       "4      jackie inlet 3 river plant shut 10 19 99 day f...      0   \n",
       "...                                                  ...    ...   \n",
       "33102  welcome gigapharm onlinne shop prescri linecan...      1   \n",
       "33103  earlier expect wrap cautiously impressed speed...      1   \n",
       "33104  ready rock rise solitude show society show tal...      1   \n",
       "33105           learn 5 10 time longer bed read plod net      1   \n",
       "33106  software give link http 6 zk net softyourmeans...      1   \n",
       "\n",
       "       length_message  length_subject  urls_count  special_chars_count  \\\n",
       "0                4282              24           0                    1   \n",
       "1                  38              28           0                    0   \n",
       "2                1171              10           0                    0   \n",
       "3                1124              25           0                    0   \n",
       "4                 534              24           0                    0   \n",
       "...               ...             ...         ...                  ...   \n",
       "33102             281              82           0                    2   \n",
       "33103             803              99           1                    1   \n",
       "33104             317              37           0                    1   \n",
       "33105              74              30           0                    0   \n",
       "33106             304              32           1                    1   \n",
       "\n",
       "       urgent_phrase_count  forwarded   msg_neg   msg_neu   msg_pos   sub_neg  \\\n",
       "0                        1          1  0.017629  0.906160  0.076210  0.065139   \n",
       "1                        0          0  0.035552  0.877274  0.087174  0.051015   \n",
       "2                        0          1  0.031416  0.934020  0.034564  0.265126   \n",
       "3                        0          1  0.035840  0.921378  0.042782  0.058819   \n",
       "4                        3          0  0.078795  0.898731  0.022474  0.043723   \n",
       "...                    ...        ...       ...       ...       ...       ...   \n",
       "33102                    0          0  0.008647  0.128509  0.862844  0.030983   \n",
       "33103                    2          0  0.015938  0.236931  0.747131  0.026812   \n",
       "33104                    0          0  0.042042  0.837309  0.120649  0.032800   \n",
       "33105                    0          0  0.045250  0.870471  0.084279  0.029581   \n",
       "33106                    0          0  0.012002  0.759813  0.228184  0.027181   \n",
       "\n",
       "        sub_neu   sub_pos  \n",
       "0      0.728012  0.206849  \n",
       "1      0.819466  0.129519  \n",
       "2      0.658116  0.076759  \n",
       "3      0.878761  0.062419  \n",
       "4      0.874298  0.081979  \n",
       "...         ...       ...  \n",
       "33102  0.886038  0.082979  \n",
       "33103  0.882739  0.090448  \n",
       "33104  0.705230  0.261970  \n",
       "33105  0.756366  0.214053  \n",
       "33106  0.608512  0.364307  \n",
       "\n",
       "[33107 rows x 15 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, results_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379758f",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a02e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# found that a lot of 2 digit numbers appeared in the top frequencies\n",
    "import re\n",
    "def remove_two_digit_numbers(text):\n",
    "    return re.sub(r'\\b\\d{2}\\b', '', text)\n",
    "\n",
    "df['Message'] = df['Message'].apply(remove_two_digit_numbers)\n",
    "df['Subject'] = df['Subject'].apply(remove_two_digit_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "074ab83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33107 entries, 0 to 33106\n",
      "Columns: 400 entries, msg_freq_000 to sub_freq_year\n",
      "dtypes: float64(400)\n",
      "memory usage: 101.0 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_msg = TfidfVectorizer(max_features=300, ngram_range=(1, 2))\n",
    "X_msg = tfidf_msg.fit_transform(df['Message'])\n",
    "X_msg = pd.DataFrame(X_msg.toarray(), columns=('msg_freq_' + word for word in tfidf_msg.get_feature_names_out()))\n",
    "\n",
    "tfidf_sub = TfidfVectorizer(max_features=100, ngram_range=(1, 2))\n",
    "X_sub = tfidf_sub.fit_transform(df['Subject'])\n",
    "X_sub = pd.DataFrame(X_sub.toarray(), columns=('sub_freq_' + word for word in tfidf_sub.get_feature_names_out()))\n",
    "\n",
    "bdf = pd.concat([X_msg, X_sub], axis=1)\n",
    "bdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15a38fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_freq_000</th>\n",
       "      <th>msg_freq_100</th>\n",
       "      <th>msg_freq_2000</th>\n",
       "      <th>msg_freq_2000 pm</th>\n",
       "      <th>msg_freq_2001</th>\n",
       "      <th>msg_freq_2001 pm</th>\n",
       "      <th>msg_freq_2004</th>\n",
       "      <th>msg_freq_2005</th>\n",
       "      <th>msg_freq_500</th>\n",
       "      <th>msg_freq_713</th>\n",
       "      <th>...</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>urgent_phrase_count</th>\n",
       "      <th>forwarded</th>\n",
       "      <th>msg_neg</th>\n",
       "      <th>msg_neu</th>\n",
       "      <th>msg_pos</th>\n",
       "      <th>sub_neg</th>\n",
       "      <th>sub_neu</th>\n",
       "      <th>sub_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140131</td>\n",
       "      <td>0.031776</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.906160</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.065139</td>\n",
       "      <td>0.728012</td>\n",
       "      <td>0.206849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035552</td>\n",
       "      <td>0.877274</td>\n",
       "      <td>0.087174</td>\n",
       "      <td>0.051015</td>\n",
       "      <td>0.819466</td>\n",
       "      <td>0.129519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.934020</td>\n",
       "      <td>0.034564</td>\n",
       "      <td>0.265126</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.076759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035840</td>\n",
       "      <td>0.921378</td>\n",
       "      <td>0.042782</td>\n",
       "      <td>0.058819</td>\n",
       "      <td>0.878761</td>\n",
       "      <td>0.062419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078795</td>\n",
       "      <td>0.898731</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>0.874298</td>\n",
       "      <td>0.081979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33102</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.128509</td>\n",
       "      <td>0.862844</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.082979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33103</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.236931</td>\n",
       "      <td>0.747131</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>0.882739</td>\n",
       "      <td>0.090448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33104</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042042</td>\n",
       "      <td>0.837309</td>\n",
       "      <td>0.120649</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.705230</td>\n",
       "      <td>0.261970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33105</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>0.870471</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.029581</td>\n",
       "      <td>0.756366</td>\n",
       "      <td>0.214053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33106</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.228184</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>0.608512</td>\n",
       "      <td>0.364307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33107 rows × 413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       msg_freq_000  msg_freq_100  msg_freq_2000  msg_freq_2000 pm  \\\n",
       "0          0.488862           0.0            0.0               0.0   \n",
       "1          0.000000           0.0            0.0               0.0   \n",
       "2          0.000000           0.0            0.0               0.0   \n",
       "3          0.000000           0.0            0.0               0.0   \n",
       "4          0.000000           0.0            0.0               0.0   \n",
       "...             ...           ...            ...               ...   \n",
       "33102      0.000000           0.0            0.0               0.0   \n",
       "33103      0.000000           0.0            0.0               0.0   \n",
       "33104      0.000000           0.0            0.0               0.0   \n",
       "33105      0.000000           0.0            0.0               0.0   \n",
       "33106      0.000000           0.0            0.0               0.0   \n",
       "\n",
       "       msg_freq_2001  msg_freq_2001 pm  msg_freq_2004  msg_freq_2005  \\\n",
       "0                0.0               0.0            0.0            0.0   \n",
       "1                0.0               0.0            0.0            0.0   \n",
       "2                0.0               0.0            0.0            0.0   \n",
       "3                0.0               0.0            0.0            0.0   \n",
       "4                0.0               0.0            0.0            0.0   \n",
       "...              ...               ...            ...            ...   \n",
       "33102            0.0               0.0            0.0            0.0   \n",
       "33103            0.0               0.0            0.0            0.0   \n",
       "33104            0.0               0.0            0.0            0.0   \n",
       "33105            0.0               0.0            0.0            0.0   \n",
       "33106            0.0               0.0            0.0            0.0   \n",
       "\n",
       "       msg_freq_500  msg_freq_713  ...  urls_count  special_chars_count  \\\n",
       "0          0.140131      0.031776  ...           0                    1   \n",
       "1          0.000000      0.000000  ...           0                    0   \n",
       "2          0.000000      0.000000  ...           0                    0   \n",
       "3          0.000000      0.000000  ...           0                    0   \n",
       "4          0.000000      0.000000  ...           0                    0   \n",
       "...             ...           ...  ...         ...                  ...   \n",
       "33102      0.000000      0.000000  ...           0                    2   \n",
       "33103      0.000000      0.000000  ...           1                    1   \n",
       "33104      0.000000      0.000000  ...           0                    1   \n",
       "33105      0.000000      0.000000  ...           0                    0   \n",
       "33106      0.000000      0.000000  ...           1                    1   \n",
       "\n",
       "       urgent_phrase_count  forwarded   msg_neg   msg_neu   msg_pos   sub_neg  \\\n",
       "0                        1          1  0.017629  0.906160  0.076210  0.065139   \n",
       "1                        0          0  0.035552  0.877274  0.087174  0.051015   \n",
       "2                        0          1  0.031416  0.934020  0.034564  0.265126   \n",
       "3                        0          1  0.035840  0.921378  0.042782  0.058819   \n",
       "4                        3          0  0.078795  0.898731  0.022474  0.043723   \n",
       "...                    ...        ...       ...       ...       ...       ...   \n",
       "33102                    0          0  0.008647  0.128509  0.862844  0.030983   \n",
       "33103                    2          0  0.015938  0.236931  0.747131  0.026812   \n",
       "33104                    0          0  0.042042  0.837309  0.120649  0.032800   \n",
       "33105                    0          0  0.045250  0.870471  0.084279  0.029581   \n",
       "33106                    0          0  0.012002  0.759813  0.228184  0.027181   \n",
       "\n",
       "        sub_neu   sub_pos  \n",
       "0      0.728012  0.206849  \n",
       "1      0.819466  0.129519  \n",
       "2      0.658116  0.076759  \n",
       "3      0.878761  0.062419  \n",
       "4      0.874298  0.081979  \n",
       "...         ...       ...  \n",
       "33102  0.886038  0.082979  \n",
       "33103  0.882739  0.090448  \n",
       "33104  0.705230  0.261970  \n",
       "33105  0.756366  0.214053  \n",
       "33106  0.608512  0.364307  \n",
       "\n",
       "[33107 rows x 413 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add additional features to new data frame\n",
    "columns_to_add = df.drop(columns={'Message', 'Subject'}).columns\n",
    "bdf[columns_to_add] = df[columns_to_add]\n",
    "bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6264d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32544 entries, 0 to 32543\n",
      "Columns: 413 entries, msg_freq_000 to sub_pos\n",
      "dtypes: float32(6), float64(400), int64(7)\n",
      "memory usage: 101.8 MB\n"
     ]
    }
   ],
   "source": [
    "# drop rows with 0 across all word frequencies\n",
    "bdf = bdf.loc[~(bdf[bdf.drop(columns=columns_to_add).columns] == 0).all(axis=1)]\n",
    "bdf = bdf.reset_index(drop=True)\n",
    "bdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca4fea-098e-4f63-af2c-9892a0e7b5e9",
   "metadata": {},
   "source": [
    "# Export dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1e20ab8-a44d-41b1-80ba-71a7193ff55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "def save_dataset(df, name, dir):\n",
    "    save_path = os.path.join(dir, f'{name}.pkl')\n",
    "    with open(save_path, 'wb') as file:\n",
    "        pickle.dump(df, file)\n",
    "\n",
    "save_dataset(bdf, 'clean_enron_spam_data', 'data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
